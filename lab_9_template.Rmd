---
title: "Lab 9 - Multiple Linear Regression"
author: "Sam Smith"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Use this template to follow along in Lab Week 9. Each code chunk you'll need is already created and named. 

**Lab 9 Objectives:**

- Explore multivariate data (SLO housing prices)
- Perform multiple linear regression
- Assess diagnostics
- Compare different models by AIC
- Explain model outputs
- Make a nice table of regression results
- Make predictions using a final model
- Visualize predictions with original data

###1. Load packages

- tidyverse
- stargazer

```{r packages, include = FALSE}

# a. Load packages 'tidyverse' and 'stargazer':

library(tidyverse)
library(stargazer)


```

###2. Load data (slo_homes.csv) as a df called 'homes', then filter to create a data frame called 'homes_sub' that only include homes in SLO, Arroyo Grande, Santa Maria-Orcutt, and Atascadero

```{r get_data, include = FALSE}

# a. Read in data as 'homes':

homes <- read_csv("slo_homes.csv")

# b. Filter to only include cities "San Luis Obispo", "Santa Maria-Orcutt", "Atascadero", and "Arroyo Grande", and call this new subset 'homes_sub':

homes_sub <- homes %>%
  filter(City=="Arroyo Grande" | City=="San Luis Obispo" | City=="Atascadero" | City=="Santa Maria-Orcutt")
homes_sub

```

###3. Go exploring (visual) + think critically about variables

*Note: It's OK to LOOK at things separately, even if you're including all in a model together!*

Example: if we want to compare distribution of housing prices by CITY (ignoring all other variables), we can do that:

```{r by_city}

# a. Calculate mean price by city
mean_by_city <- homes_sub %>% 
  group_by(City) %>% 
  summarize(
    mean = mean(Price)
  )

# b. Visualize prices by city
by_city <- ggplot(homes_sub, aes(x = Price)) +
  geom_density(aes(color = City, fill = City), alpha = 0.3) + # Note: just to show what the geom_violin shows
  theme_classic() +
  scale_x_continuous(expand = c(0,0), limits = c(0,3e6)) +
  scale_y_continuous(expand = c(0,0)) +
  labs(x = "Home Prices (USD)", y = "Density")

by_city

```

Or another question: Overall relationship between home square footage and price, separated by City? 

```{r by_sqft}

# a. Relationship between square footage and price
by_sqft <- ggplot(homes_sub, aes(x = SqFt, y = Price)) +
  geom_point(aes(color = City, pch = Status), alpha = 0.5) +
  facet_wrap(~Status)

by_sqft

# Observations here: Does relationship appear ~ linear? Anything else we can pick out re: trends, outliers, etc.? What is the general trend? Any outliers? Is there reason enough for us to omit it?

#NOTES: yes, appears linear. also think that its due to random chance
#residuals? have to create the model first!! 

```

###4. Multiple linear regression

Multiple linear regression in R follows the same syntax we've been using so far: 

    lm(y ~ x1 + x2 + x3..., data = df_name)
    
Let's try this model a couple of different ways: 

(1) Use all available variables (saturated model) 
(2) Use only SqFt as a predictor for "home size" generally (omit Bathrooms and Bedrooms), and omit PricePerSqFt (since it's derived from two other existing variables in the model)

Use summary() to view the model output and statistics.

```{r saturated}

# a. Saturated model: 

homes_lm1 <- lm(Price ~ City + Bedrooms + Bathrooms + SqFt + PricePerSqFt + Status, data = homes_sub)
#this mean home price as a function of all the variables after the tilde
#not a good model because price per square foot is included and this variable is calc using output variable so its like using a perfectly correlated variable in the model--leads to bias overfitting of model results. 
#BAD MODEL, DOESNT MAKE SENSE

#also concerning: co-linerarity: idea that if multiple variables exist in a model that are highly correlated, then the model wont make sense
#in this model, these three are the same: bedrooms, bathrooms, square feet (all tell you the same thing about the size of the house)
#might want to get rid of some of these

#equation: Price= -626690 - 76863(SLO)-9068.2(Atasc) + 120160(SM-Orcutt)

#remember that some variables arent included because they are the reference variables!

# b. Model summary:

summary(homes_lm1)

```

The next model: Exclude price per square foot, and bedrooms/bathrooms (since these are largely explained by square footage...)

```{r subset}

# a. Updated model with variables City, SqFt, and Status:

homes_lm2 <- lm(Price ~ City + SqFt + Status, data = homes_sub)
homes_lm2

#Interpretation: looking at coeff for SLO and price, if you had two houses that were exactly the same in terms of all the other variables, then the house in SLO would sell for $34,525 more in SLO than Arroyo Grande
# for every 1 sq ft increase in housing size, price would go up by $245 sq ft.

# b. Model summary:

summary(homes_lm2)

#look at the p-values for variables not the intercept! and the overall model outcome!
#use adjusted R2 for multiple-variable



```

Wait...but what if I wanted everything to be with respect to a Regular sale status? Then I need to change my factor levels. We've done this before, here we'll use a different function (fct_relevel) from *forcats* package in the tidyverse. 

```{r fct_relevel}

# a. Set Status to class 'factor'

#check class of City--- its a characters
#make it a factor!!
homes_sub$Status <- factor(homes_sub$Status)

# b. Check to ensure it's a factor now

#use class function in console to check!

# c. Check levels:

#Tells you the ORDER- NOTE that the first one is the reference one!
levels(homes_sub$Status)

# d. Reassign reference level of "Status" to "Regular":

#this way "Regular" is your reference level because that is more intuitive and more houses are sold as regular houses.

homes_sub$Status <- fct_relevel(homes_sub$Status, "Regular")

# e. Now run the regression again - same equation, but now the reference level is different (Status = Regular): 

homes_lm3 <- lm(Price ~ City + SqFt + Status, data=homes_sub)
homes_lm3

#note that however you run the model interpretation (whichever the reference levels are), the results should be the same. Ex. price of foreclosure and short sale compared to Regular houses
```

Interpret the coefficients and statistical outcomes above. 
Notes: 

###5. Model diagnostics

Remember, since we're concerned about *residuals* (distance that actual observations exist from model predictions), we can only evaluate some assumptions *after* running the regression. 

Then we can evaluate model diagnostics using the plot() function:

```{r diagnostics}

# a. Model diagnostics:

plot(homes_lm3)

#looks pretty even in terms of variance
#even though there are a few outliers, do NOT remove them! ONLY remove if they are truly not representative of your data. dont use this plot to make decisions about outliers! IGNORE THE RED LINES

#residuals variance (spread)- yes
# qqplot- yessssss
# dont really need to look at the others

#overall, heteroscedasciticty is okay, residuals normality definitey looks good, and conceptually and mathmatically my model makes sense!

```

###6. Model comparison by Akaike Information Criterion

The AIC is a quantitative metric for model "optimization" that balances complexity with model fit. The best models are the ones that fit the data as well as possible, as simply as possible. Recall: lower AIC value indicates a *more optimal* balance - **BUT STATISTICS IS NO SUBSTITUTE FOR JUDGEMENT!!!**

```{r AIC}

# a. AIC values for each model

# Answer: which would you pick? 

```

###7. Regression tables with *stargazer*

```{r stargazer, results = 'asis'}

# a. Prepare a nice regression table:



# Note: If you want to work with this in Word, save to html, open, copy and paste into Word. 

```

###8. Making predictions

Using your final selected model, predict the housing price for a range of home sizes, sale status, and city. 

The predict() function uses the following syntax:

      predict(model_name, newdata = new_data_name)
      
Defaults are to exclude the prediction SE and mean confidence interval - if you want to include, use arguments

      se.fit = TRUE
      interval = "confidence" 
      interval = "prediction"

First, you need to create a new data frame of values that contain ALL NECESSARY VARIABLES **with the same variable names AND level strings**.

```{r df_new}

# First, make a new data frame

# Note that the df_new created below has the SAME variable names and level strings as the original model data (otherwise R won't know how to use it...)
# Work through this on your own to figure out what it actually does:

df_new <- data.frame(City = rep(c("San Luis Obispo",
                                  "Santa Maria-Orcutt",
                                  "Atascadero",
                                  "Arroyo Grande"), 
                                each = 60), 
                     SqFt = rep(seq(from = 500,
                                    to = 3500, 
                                    length = 20), 
                                times = 12), 
                     Status = rep(c("Regular",
                                    "Foreclosure",
                                    "Short Sale"), 
                                  times = 12, 
                                  each = 20))

```

Make predictions for the new data using predict():

```{r predict}

# a. Make predictions using the new data frame:

# b. Bind predictions to the data to make it actually useful:



```

Then visualize it!

```{r graph, echo = FALSE}

# Create a line graph with square footage on the x-axis, predicted price on y-axis, with color dependent on City and facet_wrapped by sale status (follow along):


```

END LAB